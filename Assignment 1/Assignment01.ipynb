{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "355398be-ccac-4c01-a077-dc7e7a229602",
   "metadata": {},
   "source": [
    "# # AI Bootcamp Assignment 1 Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5e0690f-59b6-4f25-87c9-402e76d9577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libs and packs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30fe3093-a51c-4f1a-a38e-1cb3a10c2784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0570bca-8cac-437c-97f7-ef29be3648c8",
   "metadata": {},
   "source": [
    "# task 01: Load the Dataset\n",
    "<ol>\n",
    "\n",
    "<li>Import necessary libraries</li>\n",
    "<li>Load the dataset</li>\n",
    "<li>Display the first five rows of the dataset </li>\n",
    "</ol>\n",
    "\n",
    "**Expected Output: The first five rows of the dataset.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f77712ef-e987-4cd8-a420-faa992bd3fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully\n",
      "Dataset shape: (891, 15)\n"
     ]
    }
   ],
   "source": [
    "#using pandas\n",
    "df = pd.read_csv('datasets/titanic/train.csv') # load datasets\n",
    "\n",
    "df.shape\n",
    "\n",
    "#using seaborn's built in titanic\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "print(\"Dataset loaded successfully\")\n",
    "print(f\"Dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e54cdbf-c057-4aea-a5ea-4143b8542206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare  ...  class    who adult_male  deck  embark_town alive  alone\n",
       "0         0       3    male  22.0      1      0   7.2500  ...  Third    man       True   NaN  Southampton    no  False\n",
       "1         1       1  female  38.0      1      0  71.2833  ...  First  woman      False     C    Cherbourg   yes  False\n",
       "2         1       3  female  26.0      0      0   7.9250  ...  Third  woman      False   NaN  Southampton   yes   True\n",
       "3         1       1  female  35.0      1      0  53.1000  ...  First  woman      False     C  Southampton   yes  False\n",
       "4         0       3    male  35.0      0      0   8.0500  ...  Third    man       True   NaN  Southampton    no   True\n",
       "\n",
       "[5 rows x 15 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() #print first 5 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baea9108-f050-44a3-9e4b-4bf174ea5924",
   "metadata": {},
   "source": [
    "# task 02 : Handle Missing Values\n",
    "\n",
    "<ol>\n",
    "<li>Identify missing values in each column </li>\n",
    "<li>Drop columns with too many missing values (threshold: more than 50% missing) </li>\n",
    "<li>Fill missing numerical values with the median of the respective column </li>\n",
    "<li>Fill missing categorical values with the most frequent value (mode) </li>\n",
    "</ol>\n",
    "\n",
    "**Expected Output: A cleaned dataset without missing values.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4360c06d-a98e-4af1-845c-906a10cc9b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Missing Count  Missing Percentage\n",
      "age                    177           19.865320\n",
      "embarked                 2            0.224467\n",
      "deck                   688           77.216611\n",
      "embark_town              2            0.224467\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (df.isnull().sum() / len(df)) * 100\n",
    "missing_info = pd.DataFrame({\n",
    "    'Missing Count': missing_values,\n",
    "    'Missing Percentage': missing_percentage\n",
    "})\n",
    "print(missing_info[missing_info['Missing Count'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9f1f1f0-290d-4445-874a-9efa00e1cd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns to drop (>50% missing): ['deck']\n",
      "Dropped 1 columns\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "threshold = 0.5\n",
    "columns_to_drop = missing_info[missing_info['Missing Percentage'] > 50].index.tolist()\n",
    "if columns_to_drop:\n",
    "    print(f\"\\nColumns to drop (>50% missing): {columns_to_drop}\")\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "    print(f\"Dropped {len(columns_to_drop)} columns\")\n",
    "else:\n",
    "    print(\"\\nNo columns have more than 50% missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5b6114e-a696-4f1e-8a74-e46ff555c732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numerical columns: ['survived', 'pclass', 'age', 'sibsp', 'parch', 'fare']\n",
      "Filled missing values in 'age' with median: 28.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aarya\\AppData\\Local\\Temp\\ipykernel_10216\\2404801702.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(median_value, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "numerical_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"\\nNumerical columns: {numerical_columns}\")\n",
    "\n",
    "for col in numerical_columns:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        median_value = df[col].median()\n",
    "        df[col].fillna(median_value, inplace=True)\n",
    "        print(f\"Filled missing values in '{col}' with median: {median_value:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cdc18b3-0e6f-4767-9a2f-0ad29562ea7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Categorical columns: ['sex', 'embarked', 'class', 'who', 'embark_town', 'alive']\n",
      " Filled missing values in 'embarked' with mode: 'S'\n",
      " Filled missing values in 'embark_town' with mode: 'Southampton'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aarya\\AppData\\Local\\Temp\\ipykernel_10216\\3920548069.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(mode_value, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "categorical_columns = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "print(f\"\\nCategorical columns: {categorical_columns}\")\n",
    "\n",
    "for col in categorical_columns:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        mode_value = df[col].mode().iloc[0]\n",
    "        df[col].fillna(mode_value, inplace=True)\n",
    "        print(f\" Filled missing values in '{col}' with mode: '{mode_value}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e620f7dd-6cb0-4bee-b8da-707fd49b4c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values after cleaning:\n",
      "Total missing values: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nMissing values after cleaning:\")\n",
    "remaining_missing = df.isnull().sum().sum()\n",
    "print(f\"Total missing values: {remaining_missing}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05cb7b0-5540-4173-9ce9-745553386b4d",
   "metadata": {},
   "source": [
    "# task 03: Handle Duplicate Data\n",
    "<ol>\n",
    "    <li>Check for duplicate rows </li>\n",
    "    <li>Remove duplicate rows </li>\n",
    "</ol>\n",
    "\n",
    "**Expected Output: The number of duplicate rows found and removed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00fda703-c0a9-4784-83a2-55f438beb9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows found: 116\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "initial_rows = len(df)\n",
    "duplicate_count = df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows found: {duplicate_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51ff49e9-02ba-42cc-b4f3-8d565dbf9d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 116 duplicate rows\n",
      "Dataset shape after removing duplicates: (775, 14)\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "\n",
    "if duplicate_count > 0:\n",
    "    df = df.drop_duplicates()\n",
    "    final_rows = len(df)\n",
    "    removed_rows = initial_rows - final_rows\n",
    "    print(f\"Removed {removed_rows} duplicate rows\")\n",
    "    print(f\"Dataset shape after removing duplicates: {df.shape}\")\n",
    "else:\n",
    "    print(\"No duplicate rows found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59328b0a-5e3f-4377-8025-0449d6bf0695",
   "metadata": {},
   "source": [
    "# task 04: Convert Categorical Features to Numeric\n",
    "<ol>\n",
    "<li>Convert categorical columns (sex, embark_town, class, etc.) using one-hot encoding </li>\n",
    "<li>Convert Boolean columns (alone, who) to numeric (0 and 1)</li>\n",
    "\n",
    "</ol>\n",
    "\n",
    "**Expected Output: The dataset with all categorical columns transformed into numeric values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75569880-0280-4c8f-b088-c98d45d625e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns for one-hot encoding: ['sex', 'embarked', 'class', 'who', 'embark_town', 'alive']\n",
      "Applied one-hot encoding to 6 columns\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "\n",
    "df_encoded = df.copy()\n",
    "\n",
    "# 1. Convert categorical columns using one-hot encoding\n",
    "categorical_for_encoding = []\n",
    "for col in df_encoded.columns:\n",
    "    if df_encoded[col].dtype == 'object' or df_encoded[col].dtype.name == 'category':\n",
    "        categorical_for_encoding.append(col)\n",
    "\n",
    "print(f\"Categorical columns for one-hot encoding: {categorical_for_encoding}\")\n",
    "\n",
    "if categorical_for_encoding:\n",
    "    # Apply one-hot encoding\n",
    "    df_encoded = pd.get_dummies(df_encoded, columns=categorical_for_encoding, prefix=categorical_for_encoding)\n",
    "    print(f\"Applied one-hot encoding to {len(categorical_for_encoding)} columns\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d5b6f71-bce4-44f7-8b14-1c73d56f5634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boolean columns to convert: ['adult_male', 'alone', 'sex_female', 'sex_male', 'embarked_C', 'embarked_Q', 'embarked_S', 'class_First', 'class_Second', 'class_Third', 'who_child', 'who_man', 'who_woman', 'embark_town_Cherbourg', 'embark_town_Queenstown', 'embark_town_Southampton', 'alive_no', 'alive_yes']\n",
      "Converted boolean column 'adult_male' to numeric\n",
      "Converted boolean column 'alone' to numeric\n",
      "Converted boolean column 'sex_female' to numeric\n",
      "Converted boolean column 'sex_male' to numeric\n",
      "Converted boolean column 'embarked_C' to numeric\n",
      "Converted boolean column 'embarked_Q' to numeric\n",
      "Converted boolean column 'embarked_S' to numeric\n",
      "Converted boolean column 'class_First' to numeric\n",
      "Converted boolean column 'class_Second' to numeric\n",
      "Converted boolean column 'class_Third' to numeric\n",
      "Converted boolean column 'who_child' to numeric\n",
      "Converted boolean column 'who_man' to numeric\n",
      "Converted boolean column 'who_woman' to numeric\n",
      "Converted boolean column 'embark_town_Cherbourg' to numeric\n",
      "Converted boolean column 'embark_town_Queenstown' to numeric\n",
      "Converted boolean column 'embark_town_Southampton' to numeric\n",
      "Converted boolean column 'alive_no' to numeric\n",
      "Converted boolean column 'alive_yes' to numeric\n",
      "\n",
      "Dataset shape after categorical encoding: (775, 24)\n",
      "All columns are now numeric: True\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "boolean_columns = df_encoded.select_dtypes(include=[bool]).columns.tolist()\n",
    "if boolean_columns:\n",
    "    print(f\"Boolean columns to convert: {boolean_columns}\")\n",
    "    for col in boolean_columns:\n",
    "        df_encoded[col] = df_encoded[col].astype(int)\n",
    "        print(f\"Converted boolean column '{col}' to numeric\")\n",
    "else:\n",
    "    print(\"No boolean columns found to convert\")\n",
    "\n",
    "print(f\"\\nDataset shape after categorical encoding: {df_encoded.shape}\")\n",
    "print(f\"All columns are now numeric: {df_encoded.select_dtypes(include=[np.number]).shape[1] == df_encoded.shape[1]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbeb3073-6a3d-4263-b677-7582488c7713",
   "metadata": {},
   "source": [
    "# task 05: Feature Scaling\n",
    "<ol> \n",
    "<li>Normalize numerical features (age, fare, etc.) using Min-Max Scaling </li>\n",
    "<li>Standardize numerical features using StandardScaler and compare results </li>\n",
    "</ol> \n",
    "\n",
    "**Expected Output: A scaled dataset where all numerical features are normalized/standardized.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "baf7c013-6ba7-4443-b2d0-4ff459814e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous features to scale: ['pclass', 'age', 'sibsp', 'parch', 'fare']\n",
      "\n",
      "Min-Max Scaling applied\n",
      "Sample of Min-Max scaled data:\n",
      "   pclass       age  sibsp  parch      fare\n",
      "0     1.0  0.271174  0.125    0.0  0.014151\n",
      "1     0.0  0.472229  0.125    0.0  0.139136\n",
      "2     1.0  0.321438  0.000    0.0  0.015469\n",
      "3     0.0  0.434531  0.125    0.0  0.103644\n",
      "4     1.0  0.434531  0.000    0.0  0.015713\n",
      "Min-Max scaled ranges:\n",
      "  pclass: [0.000, 1.000]\n",
      "  age: [0.000, 1.000]\n",
      "  sibsp: [0.000, 1.000]\n",
      "  parch: [0.000, 1.000]\n",
      "  fare: [0.000, 1.000]\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "\n",
    "continuous_features = []\n",
    "for col in df_encoded.columns:\n",
    "    # Skip binary columns (those with only 0 and 1 values)\n",
    "    unique_values = df_encoded[col].nunique()\n",
    "    if unique_values > 2 and df_encoded[col].dtype in [np.float64, np.int64]:\n",
    "        continuous_features.append(col)\n",
    "\n",
    "print(f\"Continuous features to scale: {continuous_features}\")\n",
    "\n",
    "if continuous_features:\n",
    "    # 1. Min-Max Scaling\n",
    "    scaler_minmax = MinMaxScaler()\n",
    "    df_minmax = df_encoded.copy()\n",
    "    df_minmax[continuous_features] = scaler_minmax.fit_transform(df_encoded[continuous_features])\n",
    "    \n",
    "    print(\"\\nMin-Max Scaling applied\")\n",
    "    print(\"Sample of Min-Max scaled data:\")\n",
    "    print(df_minmax[continuous_features].head())\n",
    "    print(f\"Min-Max scaled ranges:\")\n",
    "    for col in continuous_features:\n",
    "        print(f\"  {col}: [{df_minmax[col].min():.3f}, {df_minmax[col].max():.3f}]\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7cf7bbd-1c8c-4c67-b91a-b41cc619e959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Standard Scaling applied\n",
      "Sample of Standard scaled data:\n",
      "     pclass       age     sibsp     parch      fare\n",
      "0  0.883385 -0.551060  0.475876 -0.500754 -0.527515\n",
      "1 -1.461216  0.611945  0.475876 -0.500754  0.695086\n",
      "2  0.883385 -0.260308 -0.534545 -0.500754 -0.514627\n",
      "3 -1.461216  0.393881  0.475876 -0.500754  0.347909\n",
      "4  0.883385  0.393881 -0.534545 -0.500754 -0.512240\n",
      "Standard scaled statistics:\n",
      "  pclass: mean=-0.000, std=1.001\n",
      "  age: mean=0.000, std=1.001\n",
      "  sibsp: mean=-0.000, std=1.001\n",
      "  parch: mean=0.000, std=1.001\n",
      "  fare: mean=-0.000, std=1.001\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "\n",
    "scaler_standard = StandardScaler()\n",
    "if continuous_features:\n",
    "    df_standard = df_encoded.copy()\n",
    "    df_standard[continuous_features] = scaler_standard.fit_transform(df_encoded[continuous_features])\n",
    "\n",
    "    print(\"\\nStandard Scaling applied\")\n",
    "    print(\"Sample of Standard scaled data:\")\n",
    "    print(df_standard[continuous_features].head())\n",
    "    print(f\"Standard scaled statistics:\")\n",
    "    for col in continuous_features:\n",
    "        mean_val = df_standard[col].mean()\n",
    "        std_val = df_standard[col].std()\n",
    "        print(f\"  {col}: mean={mean_val:.3f}, std={std_val:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2113b399-185e-4075-9c1e-f7eebf5f14f8",
   "metadata": {},
   "source": [
    "# task 06: Outlier Detection using IQR Method\n",
    "<ol>\n",
    "<li>Compute the Interquartile Range (IQR) for numerical features (age, fare, etc.).</li>\n",
    "<li>Identify outliers using the 1.5 * IQR rule.</li>\n",
    "<li>Remove or replace outliers with appropriate values (e.g., mean/median).</li>\n",
    "</ol>\n",
    "\n",
    "**Expected Output: A dataset where outliers are handled using the IQR method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85f01e5b-d5d7-4ad4-87a4-b47dac74d491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier detection for continuous features:\n",
      "\n",
      "Processing column: pclass\n",
      "  Q1: 1.00, Q3: 3.00, IQR: 2.00\n",
      "  Outlier bounds: [-2.00, 6.00]\n",
      "  Outliers found: 0\n",
      "No outliers found\n",
      "\n",
      "Processing column: age\n",
      "  Q1: 21.00, Q3: 36.00, IQR: 15.00\n",
      "  Outlier bounds: [-1.50, 58.50]\n",
      "  Outliers found: 27\n",
      "Replaced 27 outliers with median: 28.00\n",
      "\n",
      "Processing column: sibsp\n",
      "  Q1: 0.00, Q3: 1.00, IQR: 1.00\n",
      "  Outlier bounds: [-1.50, 2.50]\n",
      "  Outliers found: 39\n",
      "Replaced 39 outliers with median: 0.00\n",
      "\n",
      "Processing column: parch\n",
      "  Q1: 0.00, Q3: 1.00, IQR: 1.00\n",
      "  Outlier bounds: [-1.50, 2.50]\n",
      "  Outliers found: 15\n",
      "Replaced 15 outliers with median: 0.00\n",
      "\n",
      "Processing column: fare\n",
      "  Q1: 8.05, Q3: 34.20, IQR: 26.15\n",
      "  Outlier bounds: [-31.17, 73.42]\n",
      "  Outliers found: 102\n",
      "Replaced 102 outliers with median: 15.90\n"
     ]
    }
   ],
   "source": [
    "# work with encoders\n",
    "\n",
    "df_outliers = df_encoded.copy()\n",
    "\n",
    "if continuous_features:\n",
    "    print(\"Outlier detection for continuous features:\")\n",
    "\n",
    "    outlier_info = {}\n",
    "\n",
    "    for col in continuous_features:\n",
    "        print(f\"\\nProcessing column: {col}\")\n",
    "\n",
    "        #1\n",
    "\n",
    "        Q1 = df_outliers[col].quantile(0.25)\n",
    "        Q3 = df_outliers[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        print(f\"  Q1: {Q1:.2f}, Q3: {Q3:.2f}, IQR: {IQR:.2f}\")\n",
    "\n",
    "        #2\n",
    "\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        print(f\"  Outlier bounds: [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
    "\n",
    "        # Find outliers\n",
    "        outliers_mask = (df_outliers[col] < lower_bound) | (df_outliers[col] > upper_bound)\n",
    "        outliers_count = outliers_mask.sum()\n",
    "\n",
    "        print(f\"  Outliers found: {outliers_count}\")\n",
    "\n",
    "        outlier_info[col] = {\n",
    "            'count': outliers_count,\n",
    "            'percentage': (outliers_count / len(df_outliers)) * 100,\n",
    "            'lower_bound': lower_bound,\n",
    "            'upper_bound': upper_bound\n",
    "        }\n",
    "\n",
    "\n",
    "        #3\n",
    "\n",
    "        if outliers_count > 0:\n",
    "            median_value = df_outliers[col].median()\n",
    "            df_outliers.loc[outliers_mask, col] = median_value\n",
    "            print(f\"Replaced {outliers_count} outliers with median: {median_value:.2f}\")\n",
    "        else:\n",
    "            print(\"No outliers found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "945515d7-7287-4623-8284-3891a734798b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTLIER DETECTION SUMMARY\n",
      "Total outliers found and replaced: 183\n",
      "age: 27 outliers (3.5%)\n",
      "sibsp: 39 outliers (5.0%)\n",
      "parch: 15 outliers (1.9%)\n",
      "fare: 102 outliers (13.2%)\n"
     ]
    }
   ],
   "source": [
    " # Summary of outlier detection\n",
    "\n",
    "if continuous_features:\n",
    "    print(\"OUTLIER DETECTION SUMMARY\")\n",
    "\n",
    "\n",
    "    total_outliers = sum(info['count'] for info in outlier_info.values())\n",
    "    print(f\"Total outliers found and replaced: {total_outliers}\")\n",
    "\n",
    "    for col, info in outlier_info.items():\n",
    "        if info['count'] > 0:\n",
    "            print(f\"{col}: {info['count']} outliers ({info['percentage']:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e83ef4b3-0a39-46fd-8926-e276c5addad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL PREPROCESSING SUMMARY\n",
      "Original dataset shape: (775, 14)\n",
      "Final processed dataset shape: (775, 24)\n",
      "All missing values handled: True\n",
      "All features are numeric: True\n",
      "Duplicate rows removed: 116\n",
      "Outliers handled using IQR method\n",
      "\n",
      "Processed dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 775 entries, 0 to 890\n",
      "Data columns (total 24 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   survived                 775 non-null    int64  \n",
      " 1   pclass                   775 non-null    int64  \n",
      " 2   age                      775 non-null    float64\n",
      " 3   sibsp                    775 non-null    int64  \n",
      " 4   parch                    775 non-null    int64  \n",
      " 5   fare                     775 non-null    float64\n",
      " 6   adult_male               775 non-null    int64  \n",
      " 7   alone                    775 non-null    int64  \n",
      " 8   sex_female               775 non-null    int64  \n",
      " 9   sex_male                 775 non-null    int64  \n",
      " 10  embarked_C               775 non-null    int64  \n",
      " 11  embarked_Q               775 non-null    int64  \n",
      " 12  embarked_S               775 non-null    int64  \n",
      " 13  class_First              775 non-null    int64  \n",
      " 14  class_Second             775 non-null    int64  \n",
      " 15  class_Third              775 non-null    int64  \n",
      " 16  who_child                775 non-null    int64  \n",
      " 17  who_man                  775 non-null    int64  \n",
      " 18  who_woman                775 non-null    int64  \n",
      " 19  embark_town_Cherbourg    775 non-null    int64  \n",
      " 20  embark_town_Queenstown   775 non-null    int64  \n",
      " 21  embark_town_Southampton  775 non-null    int64  \n",
      " 22  alive_no                 775 non-null    int64  \n",
      " 23  alive_yes                775 non-null    int64  \n",
      "dtypes: float64(2), int64(22)\n",
      "memory usage: 151.4 KB\n",
      "None\n",
      "\n",
      "First 5 rows of final processed dataset:\n",
      "   survived  pclass   age  sibsp  ...  embark_town_Queenstown  embark_town_Southampton  alive_no  alive_yes\n",
      "0         0       3  22.0      1  ...                       0                        1         1          0\n",
      "1         1       1  38.0      1  ...                       0                        0         0          1\n",
      "2         1       3  26.0      0  ...                       0                        1         0          1\n",
      "3         1       1  35.0      1  ...                       0                        1         0          1\n",
      "4         0       3  35.0      0  ...                       0                        1         1          0\n",
      "\n",
      "[5 rows x 24 columns]\n",
      "PREPROCESSING COMPLETED SUCCESSFULLY!\n"
     ]
    }
   ],
   "source": [
    "# FINAL SUMMARY\n",
    "\n",
    "print(\"FINAL PREPROCESSING SUMMARY\")\n",
    "\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "print(f\"Final processed dataset shape: {df_outliers.shape}\")\n",
    "print(f\"All missing values handled: {df_outliers.isnull().sum().sum() == 0}\")\n",
    "print(f\"All features are numeric: {df_outliers.select_dtypes(include=[np.number]).shape[1] == df_outliers.shape[1]}\")\n",
    "print(f\"Duplicate rows removed: {duplicate_count}\")\n",
    "print(f\"Outliers handled using IQR method\")\n",
    "\n",
    "print(\"\\nProcessed dataset info:\")\n",
    "print(df_outliers.info())\n",
    "\n",
    "print(\"\\nFirst 5 rows of final processed dataset:\")\n",
    "\n",
    "print(df_outliers.head())\n",
    "\n",
    "print(\"PREPROCESSING COMPLETED SUCCESSFULLY!\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7075ee3-7f81-42f0-aff9-646d0e9de6d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm1",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
