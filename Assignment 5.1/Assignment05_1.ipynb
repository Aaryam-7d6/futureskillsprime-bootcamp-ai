{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "127511b3-3f6a-47ac-8835-259cfe10524c",
   "metadata": {},
   "source": [
    "# Assignment 05.1: Text Preprocessing with Python  \n",
    "\n",
    "**Objective:**  \n",
    "To clean and preprocess raw text data, preparing it for further analysis or input into machine \n",
    "learning models. Students will use Python libraries such as NLTK, re, and Pandas to complete \n",
    "this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2007eeba-fd77-4ba3-a92e-4514a89a150e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libs and packs:\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "import chardet # for handeling utf-8 encoding err."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1c72236-a617-4117-b36f-6acceffe302b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected encoding: Windows-1252\n",
      "Successfully read with detected encoding: Windows-1252\n"
     ]
    }
   ],
   "source": [
    "# finding the encoding: \n",
    "file_path = 'dataset/product_reviews.csv'\n",
    "\n",
    "with open(file_path, 'rb') as f:\n",
    "    result = chardet.detect(f.read())\n",
    "\n",
    "detected_encoding = result['encoding']\n",
    "print(f\"Detected encoding: {detected_encoding}\")\n",
    "\n",
    "if detected_encoding:\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding=detected_encoding)\n",
    "        print(f\"Successfully read with detected encoding: {detected_encoding}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to read with detected encoding {detected_encoding}: {e}\")\n",
    "else:\n",
    "    print(\"Could not detect encoding.\")\n",
    "\n",
    "\n",
    "# Load data:\n",
    "\n",
    "#df = pd.read_csv('dataset/product_reviews.csv')\n",
    "df = pd.read_csv('dataset/product_reviews.csv', encoding='Windows-1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "237cbb06-0848-4cc2-8e23-ae6e876ec469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aarya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\aarya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aarya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\aarya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary NLTK data (run once)\n",
    "nltk.download('stopwords')\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "nltk.download('punkt') \n",
    "\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7caeeb6f-3cf6-4f90-9d3e-88bb06fb1597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize stemmer and lemmatizer\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Get English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Create a new column for preprocessed text\n",
    "df['Processed_Text'] = df['Review_Text'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c894573c-79d0-4f68-af41-5ed4a0078c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After initial cleaning (lowercase, punctuation, numbers removed):\n",
      "    Review_ID                                     Processed_Text\n",
      "0           1  the product is great loved it but its a bit pr...\n",
      "1           2     worst product ever wouldnt recommend to anyone\n",
      "2           3  satisfactory quality works as expected no majo...\n",
      "3           4     amazing product i would buy it again and again\n",
      "4           5      the delivery was slow but the product is good\n",
      "5           6  horrible experience the product broke after ju...\n",
      "6           7  great value for the price definitely worth buying\n",
      "7           8  the product didnt meet my expectations returni...\n",
      "8           9  im satisfied with the purchase but there are b...\n",
      "9          10  superb product excellent build quality and gre...\n",
      "10         11  the product is just okay nothing special but i...\n",
      "11         12  fast delivery and product as described would b...\n",
      "12         13  not worth the money the product feels cheap an...\n",
      "13         14  the product exceeded my expectations fantastic...\n",
      "14         15  terrible customer service but the product itse...\n",
      "15         16  very happy with the product would definitely r...\n",
      "16         17  good product but ive had better ones for the s...\n",
      "17         18  i received a defective item had to return it v...\n",
      "18         19  the product is excellent but shipping took lon...\n",
      "19         20  love the product works as advertised and worth...\n"
     ]
    }
   ],
   "source": [
    "# Perform the following text preprocessing tasks:\n",
    "def preprocess_text(text):\n",
    "    # Remove leading numbers and spaces (e.g., \"1 The product...\")\n",
    "    text = re.sub(r'^\\d+\\s*', '', text)\n",
    "    # Convert all text to lowercase.\n",
    "    text = text.lower()\n",
    "    # Remove punctuation, numbers, and special characters.\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text) # Keep only letters and spaces\n",
    "    return text\n",
    "\n",
    "df['Processed_Text'] = df['Processed_Text'].apply(preprocess_text)\n",
    "\n",
    "print(\"After initial cleaning (lowercase, punctuation, numbers removed):\")\n",
    "print(df[['Review_ID', 'Processed_Text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c561b427-6366-4e49-8db8-0b9371eed8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Tokenization:\n",
      "    Review_ID                                             Tokens\n",
      "0           1  [the, product, is, great, loved, it, but, its,...\n",
      "1           2  [worst, product, ever, wouldnt, recommend, to,...\n",
      "2           3  [satisfactory, quality, works, as, expected, n...\n",
      "3           4  [amazing, product, i, would, buy, it, again, a...\n",
      "4           5  [the, delivery, was, slow, but, the, product, ...\n",
      "5           6  [horrible, experience, the, product, broke, af...\n",
      "6           7  [great, value, for, the, price, definitely, wo...\n",
      "7           8  [the, product, didnt, meet, my, expectations, ...\n",
      "8           9  [im, satisfied, with, the, purchase, but, ther...\n",
      "9          10  [superb, product, excellent, build, quality, a...\n",
      "10         11  [the, product, is, just, okay, nothing, specia...\n",
      "11         12  [fast, delivery, and, product, as, described, ...\n",
      "12         13  [not, worth, the, money, the, product, feels, ...\n",
      "13         14  [the, product, exceeded, my, expectations, fan...\n",
      "14         15  [terrible, customer, service, but, the, produc...\n",
      "15         16  [very, happy, with, the, product, would, defin...\n",
      "16         17  [good, product, but, ive, had, better, ones, f...\n",
      "17         18  [i, received, a, defective, item, had, to, ret...\n",
      "18         19  [the, product, is, excellent, but, shipping, t...\n",
      "19         20  [love, the, product, works, as, advertised, an...\n",
      "After Stopword Removal:\n",
      "    Review_ID                                 Tokens_NoStopwords\n",
      "0           1               [product, great, loved, bit, pricey]\n",
      "1           2  [worst, product, ever, wouldnt, recommend, any...\n",
      "2           3  [satisfactory, quality, works, expected, major...\n",
      "3           4                     [amazing, product, would, buy]\n",
      "4           5                    [delivery, slow, product, good]\n",
      "5           6   [horrible, experience, product, broke, one, use]\n",
      "6           7   [great, value, price, definitely, worth, buying]\n",
      "7           8    [product, didnt, meet, expectations, returning]\n",
      "8           9  [im, satisfied, purchase, better, options, ava...\n",
      "9          10  [superb, product, excellent, build, quality, g...\n",
      "10         11  [product, okay, nothing, special, gets, job, d...\n",
      "11         12   [fast, delivery, product, described, would, buy]\n",
      "12         13      [worth, money, product, feels, cheap, flimsy]\n",
      "13         14  [product, exceeded, expectations, fantastic, p...\n",
      "14         15     [terrible, customer, service, product, decent]\n",
      "15         16  [happy, product, would, definitely, recommend,...\n",
      "16         17          [good, product, ive, better, ones, price]\n",
      "17         18  [received, defective, item, return, disappoint...\n",
      "18         19  [product, excellent, shipping, took, longer, e...\n",
      "19         20  [love, product, works, advertised, worth, ever...\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the text into individual words.\n",
    "df['Tokens'] = df['Processed_Text'].apply(nltk.word_tokenize)\n",
    "\n",
    "print(\"After Tokenization:\")\n",
    "print(df[['Review_ID', 'Tokens']])\n",
    "\n",
    "\n",
    "# Remove stopwords.\n",
    "df['Tokens_NoStopwords'] = df['Tokens'].apply(lambda tokens: [word for word in tokens if word not in stop_words])\n",
    "\n",
    "print(\"After Stopword Removal:\")\n",
    "print(df[['Review_ID', 'Tokens_NoStopwords']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d491942-f28f-4556-9ce4-2ea967c324e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Stemming:\n",
      "    Review_ID                                     Stemmed_Tokens\n",
      "0           1                [product, great, love, bit, pricey]\n",
      "1           2  [worst, product, ever, wouldnt, recommend, anyon]\n",
      "2           3  [satisfactori, qualiti, work, expect, major, i...\n",
      "3           4                        [amaz, product, would, buy]\n",
      "4           5                    [deliveri, slow, product, good]\n",
      "5           6        [horribl, experi, product, broke, one, use]\n",
      "6           7          [great, valu, price, definit, worth, buy]\n",
      "7           8             [product, didnt, meet, expect, return]\n",
      "8           9      [im, satisfi, purchas, better, option, avail]\n",
      "9          10  [superb, product, excel, build, qualiti, great...\n",
      "10         11     [product, okay, noth, special, get, job, done]\n",
      "11         12     [fast, deliveri, product, describ, would, buy]\n",
      "12         13       [worth, money, product, feel, cheap, flimsi]\n",
      "13         14        [product, exceed, expect, fantast, perform]\n",
      "14         15         [terribl, custom, servic, product, decent]\n",
      "15         16  [happi, product, would, definit, recommend, ot...\n",
      "16         17           [good, product, ive, better, one, price]\n",
      "17         18         [receiv, defect, item, return, disappoint]\n",
      "18         19       [product, excel, ship, took, longer, expect]\n",
      "19         20  [love, product, work, advertis, worth, everi, ...\n",
      "After Lemmatization:\n",
      "    Review_ID                                  Lemmatized_Tokens\n",
      "0           1               [product, great, loved, bit, pricey]\n",
      "1           2  [worst, product, ever, wouldnt, recommend, any...\n",
      "2           3  [satisfactory, quality, work, expected, major,...\n",
      "3           4                     [amazing, product, would, buy]\n",
      "4           5                    [delivery, slow, product, good]\n",
      "5           6   [horrible, experience, product, broke, one, use]\n",
      "6           7   [great, value, price, definitely, worth, buying]\n",
      "7           8     [product, didnt, meet, expectation, returning]\n",
      "8           9  [im, satisfied, purchase, better, option, avai...\n",
      "9          10  [superb, product, excellent, build, quality, g...\n",
      "10         11  [product, okay, nothing, special, get, job, done]\n",
      "11         12   [fast, delivery, product, described, would, buy]\n",
      "12         13       [worth, money, product, feel, cheap, flimsy]\n",
      "13         14  [product, exceeded, expectation, fantastic, pe...\n",
      "14         15     [terrible, customer, service, product, decent]\n",
      "15         16  [happy, product, would, definitely, recommend,...\n",
      "16         17           [good, product, ive, better, one, price]\n",
      "17         18  [received, defective, item, return, disappoint...\n",
      "18         19  [product, excellent, shipping, took, longer, e...\n",
      "19         20  [love, product, work, advertised, worth, every...\n"
     ]
    }
   ],
   "source": [
    "# Perform stemming and lemmatization.\n",
    "df['Stemmed_Tokens'] = df['Tokens_NoStopwords'].apply(lambda tokens: [stemmer.stem(word) for word in tokens])\n",
    "df['Lemmatized_Tokens'] = df['Tokens_NoStopwords'].apply(lambda tokens: [lemmatizer.lemmatize(word) for word in tokens])\n",
    "\n",
    "print(\"After Stemming:\")\n",
    "print(df[['Review_ID', 'Stemmed_Tokens']])\n",
    "\n",
    "\n",
    "print(\"After Lemmatization:\")\n",
    "print(df[['Review_ID', 'Lemmatized_Tokens']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afa3996f-e583-4e95-b3c6-3b028db1197e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns available before TF-IDF calculation: Index(['Review_ID', 'Review_Text', 'Processed_Text', 'Tokens',\n",
      "       'Tokens_NoStopwords', 'Stemmed_Tokens', 'Lemmatized_Tokens'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#For TF-IDF, it's common to use either stemmed or lemmatized tokens.\n",
    "#here, we use lemmatized tokens for a more refined analysis.\n",
    "\n",
    "# TF (Term Frequency) = 1 + log(C(w,d) + 1)\n",
    "# IDF (Inverse Document Frequency) = log(N / df(w)) where N is total documents, df(w) is documents containing word w\n",
    "\n",
    "\n",
    "print(\"Columns available before TF-IDF calculation:\", df.columns) # Add this line\n",
    "\n",
    "# For TF-IDF, it's common to use either stemmed or lemmatized tokens. Let's use lemmatized tokens for a more refined analysis.\n",
    "df['Final_Tokens'] = df['Lemmatized_Tokens']\n",
    "\n",
    "\n",
    "N = len(df) # Total number of documents (reviews)\n",
    "\n",
    "df_counts = defaultdict(int)\n",
    "for _, row in df.iterrows():\n",
    "    unique_words_in_doc = set(row['Final_Tokens'])\n",
    "    for word in unique_words_in_doc:\n",
    "        df_counts[word] += 1\n",
    "\n",
    "\n",
    "idf_scores = {}\n",
    "for word, count in df_counts.items():\n",
    "    idf_scores[word] = math.log(N / count)\n",
    "\n",
    "# Calculate TF-IDF for each review\n",
    "tfidf_list = []\n",
    "for index, row in df.iterrows():\n",
    "    tf_idf_doc = {}\n",
    "    word_counts = defaultdict(int)\n",
    "    for word in row['Final_Tokens']:\n",
    "        word_counts[word] += 1\n",
    "\n",
    "    for word, count in word_counts.items():\n",
    "        tf = 1 + math.log(count + 1) # Using the specified TF formula\n",
    "        tfidf = tf * idf_scores[word]\n",
    "        tf_idf_doc[word] = tfidf\n",
    "    tfidf_list.append(tf_idf_doc)\n",
    "\n",
    "df['TF-IDF'] = tfidf_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a825cc85-54e7-487f-b696-180598c8370c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final DataFrame with Processed Text and TF-IDF scores:\n",
      "    Review_ID                                        Review_Text  \\\n",
      "0           1  \"The product is GREAT! Loved it, but it’s a bi...   \n",
      "1           2  \"Worst product ever!! Wouldn’t recommend to an...   \n",
      "2           3  \"Satisfactory quality, works as expected, no m...   \n",
      "3           4  \"Amazing product, I would buy it again and aga...   \n",
      "4           5  \"The delivery was slow, but the product is good.\"   \n",
      "5           6  \"Horrible experience, the product broke after ...   \n",
      "6           7  \"Great value for the price! Definitely worth b...   \n",
      "7           8  \"The product didn’t meet my expectations, retu...   \n",
      "8           9  \"I’m satisfied with the purchase, but there ar...   \n",
      "9          10  \"Superb product! Excellent build quality and g...   \n",
      "10         11  \"The product is just okay, nothing special, bu...   \n",
      "11         12  \"Fast delivery and product as described. Would...   \n",
      "12         13  \"Not worth the money. The product feels cheap ...   \n",
      "13         14  \"The product exceeded my expectations. Fantast...   \n",
      "14         15  \"Terrible customer service, but the product it...   \n",
      "15         16  \"Very happy with the product. Would definitely...   \n",
      "16         17  \"Good product, but I’ve had better ones for th...   \n",
      "17         18  \"I received a defective item, had to return it...   \n",
      "18         19  \"The product is excellent, but shipping took l...   \n",
      "19         20  \"Love the product! Works as advertised and wor...   \n",
      "\n",
      "                                         Final_Tokens  \\\n",
      "0                [product, great, loved, bit, pricey]   \n",
      "1   [worst, product, ever, wouldnt, recommend, any...   \n",
      "2   [satisfactory, quality, work, expected, major,...   \n",
      "3                      [amazing, product, would, buy]   \n",
      "4                     [delivery, slow, product, good]   \n",
      "5    [horrible, experience, product, broke, one, use]   \n",
      "6    [great, value, price, definitely, worth, buying]   \n",
      "7      [product, didnt, meet, expectation, returning]   \n",
      "8   [im, satisfied, purchase, better, option, avai...   \n",
      "9   [superb, product, excellent, build, quality, g...   \n",
      "10  [product, okay, nothing, special, get, job, done]   \n",
      "11   [fast, delivery, product, described, would, buy]   \n",
      "12       [worth, money, product, feel, cheap, flimsy]   \n",
      "13  [product, exceeded, expectation, fantastic, pe...   \n",
      "14     [terrible, customer, service, product, decent]   \n",
      "15  [happy, product, would, definitely, recommend,...   \n",
      "16           [good, product, ive, better, one, price]   \n",
      "17  [received, defective, item, return, disappoint...   \n",
      "18  [product, excellent, shipping, took, longer, e...   \n",
      "19  [love, product, work, advertised, worth, every...   \n",
      "\n",
      "                                               TF-IDF  \n",
      "0   {'product': 0.3778, 'great': 3.2121, 'loved': ...  \n",
      "1   {'worst': 5.0722, 'product': 0.3778, 'ever': 5...  \n",
      "2   {'satisfactory': 5.0722, 'quality': 3.8986, 'w...  \n",
      "3   {'amazing': 5.0722, 'product': 0.3778, 'would'...  \n",
      "4   {'delivery': 3.8986, 'slow': 5.0722, 'product'...  \n",
      "5   {'horrible': 5.0722, 'experience': 5.0722, 'pr...  \n",
      "6   {'great': 3.2121, 'value': 5.0722, 'price': 3....  \n",
      "7   {'product': 0.3778, 'didnt': 5.0722, 'meet': 5...  \n",
      "8   {'im': 5.0722, 'satisfied': 5.0722, 'purchase'...  \n",
      "9   {'superb': 5.0722, 'product': 0.3778, 'excelle...  \n",
      "10  {'product': 0.3778, 'okay': 5.0722, 'nothing':...  \n",
      "11  {'fast': 5.0722, 'delivery': 3.8986, 'product'...  \n",
      "12  {'worth': 3.2121, 'money': 5.0722, 'product': ...  \n",
      "13  {'product': 0.3778, 'exceeded': 5.0722, 'expec...  \n",
      "14  {'terrible': 5.0722, 'customer': 3.8986, 'serv...  \n",
      "15  {'happy': 5.0722, 'product': 0.3778, 'would': ...  \n",
      "16  {'good': 3.8986, 'product': 0.3778, 'ive': 5.0...  \n",
      "17  {'received': 5.0722, 'defective': 5.0722, 'ite...  \n",
      "18  {'product': 0.3778, 'excellent': 3.8986, 'ship...  \n",
      "19  {'love': 5.0722, 'product': 0.3778, 'work': 3....  \n"
     ]
    }
   ],
   "source": [
    "print(\"Final DataFrame with Processed Text and TF-IDF scores:\")\n",
    "# Print the first few entries of TF-IDF for brevity\n",
    "df_display = df[['Review_ID', 'Review_Text', 'Final_Tokens', 'TF-IDF']].copy()\n",
    "df_display['TF-IDF'] = df_display['TF-IDF'].apply(lambda x: {k: round(v, 4) for k, v in list(x.items())[:5]}) # Show only top 5 TF-IDF for display\n",
    "print(df_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2869704-abbc-4992-bf99-10d3cd932e93",
   "metadata": {},
   "source": [
    "## Summary of Key Outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f617acf-2c9b-4890-acd3-c512a5ea6490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SUMMARY OF TEXT PREPROCESSING AND TF-IDF ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Final DataFrame with Processed Tokens:\n",
      "   Review_ID                                        Review_Text  \\\n",
      "0          1  \"The product is GREAT! Loved it, but it’s a bi...   \n",
      "1          2  \"Worst product ever!! Wouldn’t recommend to an...   \n",
      "2          3  \"Satisfactory quality, works as expected, no m...   \n",
      "3          4  \"Amazing product, I would buy it again and aga...   \n",
      "4          5  \"The delivery was slow, but the product is good.\"   \n",
      "5          6  \"Horrible experience, the product broke after ...   \n",
      "6          7  \"Great value for the price! Definitely worth b...   \n",
      "7          8  \"The product didn’t meet my expectations, retu...   \n",
      "8          9  \"I’m satisfied with the purchase, but there ar...   \n",
      "9         10  \"Superb product! Excellent build quality and g...   \n",
      "\n",
      "                                        Final_Tokens  \n",
      "0               [product, great, loved, bit, pricey]  \n",
      "1  [worst, product, ever, wouldnt, recommend, any...  \n",
      "2  [satisfactory, quality, work, expected, major,...  \n",
      "3                     [amazing, product, would, buy]  \n",
      "4                    [delivery, slow, product, good]  \n",
      "5   [horrible, experience, product, broke, one, use]  \n",
      "6   [great, value, price, definitely, worth, buying]  \n",
      "7     [product, didnt, meet, expectation, returning]  \n",
      "8  [im, satisfied, purchase, better, option, avai...  \n",
      "9  [superb, product, excellent, build, quality, g...  \n",
      "\n",
      "==================================================\n",
      "\n",
      "Final DataFrame with TF-IDF Scores (showing top 5 words per review):\n",
      "   Review_ID                                        Review_Text  \\\n",
      "0          1  \"The product is GREAT! Loved it, but it’s a bi...   \n",
      "1          2  \"Worst product ever!! Wouldn’t recommend to an...   \n",
      "2          3  \"Satisfactory quality, works as expected, no m...   \n",
      "3          4  \"Amazing product, I would buy it again and aga...   \n",
      "4          5  \"The delivery was slow, but the product is good.\"   \n",
      "5          6  \"Horrible experience, the product broke after ...   \n",
      "6          7  \"Great value for the price! Definitely worth b...   \n",
      "7          8  \"The product didn’t meet my expectations, retu...   \n",
      "8          9  \"I’m satisfied with the purchase, but there ar...   \n",
      "9         10  \"Superb product! Excellent build quality and g...   \n",
      "\n",
      "                                        Final_Tokens  \\\n",
      "0               [product, great, loved, bit, pricey]   \n",
      "1  [worst, product, ever, wouldnt, recommend, any...   \n",
      "2  [satisfactory, quality, work, expected, major,...   \n",
      "3                     [amazing, product, would, buy]   \n",
      "4                    [delivery, slow, product, good]   \n",
      "5   [horrible, experience, product, broke, one, use]   \n",
      "6   [great, value, price, definitely, worth, buying]   \n",
      "7     [product, didnt, meet, expectation, returning]   \n",
      "8  [im, satisfied, purchase, better, option, avai...   \n",
      "9  [superb, product, excellent, build, quality, g...   \n",
      "\n",
      "                                              TF-IDF  \n",
      "0  {'product': 0.3778, 'great': 3.2121, 'loved': ...  \n",
      "1  {'worst': 5.0722, 'product': 0.3778, 'ever': 5...  \n",
      "2  {'satisfactory': 5.0722, 'quality': 3.8986, 'w...  \n",
      "3  {'amazing': 5.0722, 'product': 0.3778, 'would'...  \n",
      "4  {'delivery': 3.8986, 'slow': 5.0722, 'product'...  \n",
      "5  {'horrible': 5.0722, 'experience': 5.0722, 'pr...  \n",
      "6  {'great': 3.2121, 'value': 5.0722, 'price': 3....  \n",
      "7  {'product': 0.3778, 'didnt': 5.0722, 'meet': 5...  \n",
      "8  {'im': 5.0722, 'satisfied': 5.0722, 'purchase'...  \n",
      "9  {'superb': 5.0722, 'product': 0.3778, 'excelle...  \n",
      "\n",
      "============================================================\n",
      "\n",
      "Summary complete.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"SUMMARY OF TEXT PREPROCESSING AND TF-IDF ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Display the Final DataFrame with preprocessed tokens\n",
    "print(\"\\nFinal DataFrame with Processed Tokens:\")\n",
    "print(df[['Review_ID', 'Review_Text', 'Final_Tokens']].head(10))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Display the TF-IDF scores for each review\n",
    "# Limiting the display to a few key TF-IDF scores per review for readability\n",
    "print(\"Final DataFrame with TF-IDF Scores (showing top 5 words per review):\")\n",
    "df_display = df[['Review_ID', 'Review_Text', 'Final_Tokens', 'TF-IDF']].copy()\n",
    "df_display['TF-IDF'] = df_display['TF-IDF'].apply(lambda x: {k: round(v, 4) for k, v in list(x.items())[:5]})\n",
    "print(df_display.head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "print(\"Summary complete.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edc65e0-4bd1-4a84-945e-d11e5c80506e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36766c67-066e-43f5-aca5-e79dc5878040",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm1",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
